{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "taXocHaCQh9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL INVERSION ATTACK ON TABULAR DATA\n",
        "\n",
        "**Dataset** : **ADULT**\n",
        "\n",
        "**Target Model** : Predicts 'income' using the features 'work', 'education', 'marital', 'occupation', 'sex', 'capitalgain', 'capitalloss', and 'hoursperweek'.\n",
        "\n",
        "**Attack Model** : Attempts to reconstruct the sensitive attribut 'race'."
      ],
      "metadata": {
        "id": "DI2kp6QZPrT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error, classification_report\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "KJFhwbHCaUUv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data load and Preprocessing for the Target Model"
      ],
      "metadata": {
        "id": "f4MGqs5CbBpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Adult_35222.csv'\n",
        "dt_adult = pd.read_csv(file_path)\n",
        "\n",
        "dt_adult['income_binary'] = dt_adult['income'].map({'<=50K': 0, '>50K': 1})\n",
        "\n",
        "X = dt_adult[['work', 'education', 'marital', 'occupation', 'sex', 'capitalgain', 'capitalloss', 'hoursperweek']]\n",
        "sensitive_feature = dt_adult['race']\n",
        "y = dt_adult['income_binary']\n",
        "\n",
        "cat_features = ['work', 'education', 'marital', 'occupation', 'sex']\n",
        "num_features = ['capitalgain', 'capitalloss', 'hoursperweek']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_features),\n",
        "    ('cat', OneHotEncoder(), cat_features)\n",
        "])\n",
        "\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "sensitive_encoder = OneHotEncoder()\n",
        "sensitive_feature_encoded = sensitive_encoder.fit_transform(sensitive_feature.values.reshape(-1, 1)).toarray()\n"
      ],
      "metadata": {
        "id": "g0HiHt9ebAT4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n",
        "    X_preprocessed, y, sensitive_feature_encoded, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "qgE4l27Sxy2x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Network**\n",
        "\n",
        "Neural network contains layers of interconnected nodes which is inspired by the human brain structure which learns from different patterns of data.\n",
        "\n",
        "Optimizer Used: Adam Optimizer(Adaptive Moment Estimation)"
      ],
      "metadata": {
        "id": "qRyO63i11Zcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "target_model = models.Sequential([\n",
        "    layers.Input(shape=(input_dim,)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "target_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "target_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "test_loss, test_accuracy = target_model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Target Model - Test Loss: {test_loss:.2f}, Test Accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7pWk5PG-DDO",
        "outputId": "7f61f5cd-f707-4315-ca78-267a2a1c09f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8040 - loss: 0.3973\n",
            "Epoch 2/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.3398\n",
            "Epoch 3/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3378\n",
            "Epoch 4/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8456 - loss: 0.3339\n",
            "Epoch 5/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3314\n",
            "Epoch 6/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.3286\n",
            "Epoch 7/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3292\n",
            "Epoch 8/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.3295\n",
            "Epoch 9/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.3229\n",
            "Epoch 10/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3316\n",
            "Epoch 11/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3270\n",
            "Epoch 12/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8501 - loss: 0.3253\n",
            "Epoch 13/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8461 - loss: 0.3268\n",
            "Epoch 14/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8520 - loss: 0.3253\n",
            "Epoch 15/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8536 - loss: 0.3225\n",
            "Epoch 16/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8520 - loss: 0.3227\n",
            "Epoch 17/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3267\n",
            "Epoch 18/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.3223\n",
            "Epoch 19/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8527 - loss: 0.3186\n",
            "Epoch 20/20\n",
            "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.3145\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.3289\n",
            "Target Model - Test Loss: 0.32, Test Accuracy: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack"
      ],
      "metadata": {
        "id": "EbBtIH8T-GFb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-B9T0rMFxje",
        "outputId": "f84d6761-43a5-47d0-adef-348d38245f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.8331\n",
            "Epoch 2/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8540 - loss: 0.5451\n",
            "Epoch 3/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.5307\n",
            "Epoch 4/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.5264\n",
            "Epoch 5/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.5356\n",
            "Epoch 6/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8524 - loss: 0.5428\n",
            "Epoch 7/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.5193\n",
            "Epoch 8/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.5403\n",
            "Epoch 9/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.5476\n",
            "Epoch 10/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.5130\n",
            "Epoch 11/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8584 - loss: 0.5208\n",
            "Epoch 12/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8739 - loss: 0.4820\n",
            "Epoch 13/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 0.4984\n",
            "Epoch 14/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.5492\n",
            "Epoch 15/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8503 - loss: 0.5444\n",
            "Epoch 16/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.5239\n",
            "Epoch 17/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.5205\n",
            "Epoch 18/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8594 - loss: 0.5246\n",
            "Epoch 19/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.5005\n",
            "Epoch 20/20\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.5451\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Mean Absolute Error (MAE) for Sensitive Feature Reconstruction: 0.0976\n"
          ]
        }
      ],
      "source": [
        "def attack_with_neural_net(target_model, X, sensitive_true, sensitive_dim, epochs=20, batch_size=32, learning_rate=0.001):\n",
        "\n",
        "    model_outputs = target_model.predict(X)\n",
        "\n",
        "    inversion_model = models.Sequential([\n",
        "        layers.Input(shape=(1,)),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(sensitive_dim, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    inversion_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                            loss='categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "\n",
        "    inversion_model.fit(model_outputs, sensitive_true, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "    reconstructed_sensitive = inversion_model.predict(model_outputs)\n",
        "    return reconstructed_sensitive\n",
        "\n",
        "reconstructed_sens_attr = attack_with_neural_net(\n",
        "    target_model, X_test, sensitive_test, sensitive_dim=sensitive_test.shape[1], epochs=20, batch_size=32, learning_rate=0.001\n",
        ")\n",
        "\n",
        "mae = mean_absolute_error(sensitive_test, reconstructed_sens_attr)\n",
        "print(f\"Mean Absolute Error (MAE) for Sensitive Feature Reconstruction: {mae:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "_qgfIHD5_aVy"
      }
    }
  ]
}